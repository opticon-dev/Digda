import openai
import base64
import json
from PIL import Image
import os
import replicate
import requests
import time
import shutil
from datetime import datetime
import io

# =============================================================================
# ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =============================================================================


def encode_image_to_base64(image_path):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def image_buffer_to_base64(image_buffer):
    return base64.b64encode(image_buffer).decode("utf-8")


class ImageProcessor:
    def __init__(self, OPENAI_API_KEY, REPLICATE_API_TOKEN):
        # 1. API í‚¤ ì„¤ì • (ì½”ë“œì˜ ë§¨ ìœ„ì— ìœ„ì¹˜)
        # OpenAI API í‚¤: https://platform.openai.com/api-keys
        self.OPENAI_API_KEY = OPENAI_API_KEY
        # Replicate API í‚¤: https://replicate.com/account/api-tokens
        REPLICATE_API_TOKEN = None

        self.open_ai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
        self.replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)

    def process_1(self, image):
        # ë‹¨ê³„ 1: ê°€êµ¬ ì¸ì‹ ë° í¬ë¡­
        print("\nğŸ”¥ [ë‹¨ê³„ 1] ê°€êµ¬ ì¸ì‹ ë° í¬ë¡­ ì‹œì‘...")
        step1_result = FurnitureCropper(self.open_ai_client).process(image)

        if not step1_result:
            print("âŒ ë‹¨ê³„ 1 ì‹¤íŒ¨: ê°€êµ¬ ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None

        print(
            f"âœ… ë‹¨ê³„ 1 ì™„ë£Œ: {len(step1_result['detected_furniture'])}ê°œ ê°€êµ¬ ì²˜ë¦¬ë¨"
        )

        # ë‹¨ê³„ 2: ë°°ê²½ ì œê±°
        print("\nğŸ”¥ [ë‹¨ê³„ 2] Bria ë°°ê²½ ì œê±° ì‹œì‘...")
        step2_result = BackgroundRemover(self.replicate_client).process()

    def run_complete_furniture_pipeline(self, image_path):
        """ê°€êµ¬ ì¸ì‹ë¶€í„° 3D ëª¨ë¸ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            print("ğŸš€" + "=" * 78)
            print("ğŸ¯ ì™„ì „í•œ ê°€êµ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€: {image_path}")
            print("ğŸš€" + "=" * 78)

            # ë‹¨ê³„ 1: ê°€êµ¬ ì¸ì‹ ë° í¬ë¡­
            print("\nğŸ”¥ [ë‹¨ê³„ 1] ê°€êµ¬ ì¸ì‹ ë° í¬ë¡­ ì‹œì‘...")
            step1_result = FurnitureCropper(self.open_ai_client).process(image_path)

            if not step1_result:
                print("âŒ ë‹¨ê³„ 1 ì‹¤íŒ¨: ê°€êµ¬ ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None

            print(
                f"âœ… ë‹¨ê³„ 1 ì™„ë£Œ: {len(step1_result['detected_furniture'])}ê°œ ê°€êµ¬ ì²˜ë¦¬ë¨"
            )

            # ë‹¨ê³„ 2: ë°°ê²½ ì œê±°
            print("\nğŸ”¥ [ë‹¨ê³„ 2] Bria ë°°ê²½ ì œê±° ì‹œì‘...")
            step2_result = BackgroundRemover(self.replicate_client).process()

            if not step2_result:
                print("âŒ ë‹¨ê³„ 2 ì‹¤íŒ¨: ë°°ê²½ ì œê±°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None

            success_count_2 = len(
                [f for f in step2_result if f.get("status") == "success"]
            )
            print(f"âœ… ë‹¨ê³„ 2 ì™„ë£Œ: {success_count_2}ê°œ íŒŒì¼ ë°°ê²½ ì œê±°ë¨")

            # ë‹¨ê³„ 3: 3D ë³€í™˜
            print("\nğŸ”¥ [ë‹¨ê³„ 3] HunYuan3D 3D ë³€í™˜ ì‹œì‘...")
            step3_result = ImgToModeling(self.replicate_client).process()

            if not step3_result:
                print("âŒ ë‹¨ê³„ 3 ì‹¤íŒ¨: 3D ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None

            success_count_3 = len(
                [f for f in step3_result if f.get("status") == "success"]
            )
            print(f"âœ… ë‹¨ê³„ 3 ì™„ë£Œ: {success_count_3}ê°œ 3D ëª¨ë¸ ìƒì„±ë¨")

            # ìµœì¢… ê²°ê³¼
            pipeline_result = {
                "source_image": image_path,
                "step1_result": step1_result,
                "step2_result": step2_result,
                "step3_result": step3_result,
                "final_stats": {
                    "detected_furniture": len(step1_result["detected_furniture"]),
                    "background_removed": success_count_2,
                    "3d_models_created": success_count_3,
                    "overall_success_rate": f"{success_count_3/len(step1_result['detected_furniture'])*100:.1f}%",
                },
            }

            # ê²°ê³¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            with open(
                f"complete_pipeline_result_{timestamp}.json", "w", encoding="utf-8"
            ) as f:
                json.dump(pipeline_result, f, ensure_ascii=False, indent=2)

            print("\nğŸ‰" + "=" * 78)
            print("ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print(f"ğŸ“Š ìµœì¢… í†µê³„:")
            print(f"   ğŸ” ì¸ì‹ëœ ê°€êµ¬: {len(step1_result['detected_furniture'])}ê°œ")
            print(f"   ğŸ­ ë°°ê²½ ì œê±°: {success_count_2}ê°œ")
            print(f"   ğŸ¨ 3D ëª¨ë¸: {success_count_3}ê°œ")
            print(
                f"   ğŸ“ˆ ì „ì²´ ì„±ê³µë¥ : {success_count_3/len(step1_result['detected_furniture'])*100:.1f}%"
            )
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: complete_pipeline_result_{timestamp}.json")
            print("ğŸ‰" + "=" * 78)

            return pipeline_result

        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return None


# =============================================================================
# ë‹¨ê³„ 1: GPT APIë¥¼ ì‚¬ìš©í•œ ê°€êµ¬ ì¸ì‹ ë° ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­ (ì¤‘ë³µ ì œê±° ë²„ì „)
# =============================================================================


def calculate_box_area(box):
    """ë°•ìŠ¤ì˜ ë©´ì  ê³„ì‚°"""
    x1, y1, x2, y2 = box
    return (x2 - x1) * (y2 - y1)


def calculate_overlap_ratio(box1, box2):
    """ë‘ ë°•ìŠ¤ì˜ ê²¹ì¹˜ëŠ” ë¹„ìœ¨ ê³„ì‚° (ì‘ì€ ë°•ìŠ¤ ê¸°ì¤€)"""
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2

    # ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
    overlap_x1 = max(x1_1, x1_2)
    overlap_y1 = max(y1_1, y1_2)
    overlap_x2 = min(x2_1, x2_2)
    overlap_y2 = min(y2_1, y2_2)

    # ê²¹ì¹˜ëŠ” ì˜ì—­ì´ ìˆëŠ”ì§€ í™•ì¸
    if overlap_x1 >= overlap_x2 or overlap_y1 >= overlap_y2:
        return 0.0

    # ê²¹ì¹˜ëŠ” ë©´ì 
    overlap_area = (overlap_x2 - overlap_x1) * (overlap_y2 - overlap_y1)

    # ë” ì‘ì€ ë°•ìŠ¤ì˜ ë©´ì 
    area1 = calculate_box_area(box1)
    area2 = calculate_box_area(box2)
    smaller_area = min(area1, area2)

    # ì‘ì€ ë°•ìŠ¤ ê¸°ì¤€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨
    return overlap_area / smaller_area if smaller_area > 0 else 0.0


class FurnitureCropper:
    def __init__(self, open_ai_client):
        self.open_ai_client = open_ai_client

    def process(self, image_path):
        """ë‹¨ê³„ 1: ì¤‘ë³µ ì œê±°ëœ ê°€êµ¬ ì¸ì‹ ë° ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­"""
        print("=" * 70)
        print("ğŸš€ ë‹¨ê³„ 1: GPT ê°€êµ¬ ì¸ì‹ + ì¤‘ë³µ ì œê±° + ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­")
        print("=" * 70)

        # 1. ê°€êµ¬ ì¸ì‹ (ì¤‘ë³µ ì œê±° í¬í•¨)
        print("\nğŸ“ 1ë‹¨ê³„: ê°€êµ¬ ì¸ì‹ ë° ì¤‘ë³µ ì œê±°")
        furniture_list = self._detect_furniture_with_gpt_filtered(image_path)

        if not furniture_list:
            print("âŒ ê°€êµ¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return None

        # 2. ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­
        print("\nğŸ“ 2ë‹¨ê³„: ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­")
        cropped_results = self.crop_furniture_centered_filtered(
            image_path, furniture_list
        )

        # 3. ìƒëŒ€ì  í¬ê¸° ë¶„ì„ ì¶”ê°€
        print("\nğŸ“ 3ë‹¨ê³„: ìƒëŒ€ì  í¬ê¸° ë¶„ì„")
        with Image.open(image_path) as img:
            img_width, img_height = img.size

        size_analysis = self.calculate_size_analysis(
            furniture_list, img_width, img_height
        )

        # 4. ê²°ê³¼ ì €ì¥ (í¬ê¸° ë¶„ì„ í¬í•¨)
        result_data = {
            "detected_furniture": furniture_list,
            "cropped_images": cropped_results,
            "size_analysis": size_analysis,  # ìƒˆë¡œ ì¶”ê°€ëœ í¬ê¸° ë¶„ì„ ì •ë³´
            "summary": {
                "total_detected": len(furniture_list),
                "successfully_cropped": len(cropped_results),
                "large_furniture": len(
                    [f for f in furniture_list if f.get("category") == "large"]
                ),
                "medium_furniture": len(
                    [f for f in furniture_list if f.get("category") == "medium"]
                ),
                "small_furniture": len(
                    [f for f in furniture_list if f.get("category") == "small"]
                ),
            },
        }
        print(result_data)
        # JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥
        with open(
            "step1_furniture_detection_filtered.json", "w", encoding="utf-8"
        ) as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)

        print("\n" + "=" * 70)
        print(f"âœ… ë‹¨ê³„ 1 ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ì„ íƒ ê°€êµ¬: {len(furniture_list)}ê°œ")
        print(f"ğŸ–¼ï¸  í¬ë¡­ëœ ì´ë¯¸ì§€: {len(cropped_results)}ê°œ")
        print(f"ğŸ“ ìƒëŒ€ì  í¬ê¸° ë¶„ì„: í¬í•¨ë¨")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: step1_furniture_detection_filtered.json")
        print("=" * 70)

        return result_data

    def _detect_furniture_with_gpt_filtered(self, image_path):
        """GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€êµ¬ë¥¼ ì¸ì‹í•˜ê³  ì¤‘ë³µ ì œê±°"""
        print(f"ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {image_path}")

        if isinstance(image_path, str):
            # íŒŒì¼ ê²½ë¡œ
            with Image.open(image_path) as img:
                img_width, img_height = img.width, img.height
            base64_image = encode_image_to_base64(image_path)

        elif isinstance(image_path, bytes):
            # raw bytes
            img = Image.open(io.BytesIO(image_path))
            img_width, img_height = img.width, img.height
            base64_image = image_buffer_to_base64(image_path)

        elif isinstance(image_path, io.BytesIO):
            # ì´ë¯¸ BytesIO ê°ì²´
            img = Image.open(image_path)
            img_width, img_height = img.width, img.height
            # BytesIO â†’ bytes ë³€í™˜í•´ì„œ base64 ì¸ì½”ë”©
            base64_image = image_buffer_to_base64(image_path.getvalue())

        else:
            raise TypeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì…: {type(image_path)}")
        # GPT í”„ë¡¬í”„íŠ¸ (ì£¼ìš” ê°€êµ¬ ì¤‘ì‹¬)
        prompt = f"""
ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ ê±°ì‹¤ ì‚¬ì§„ì—ì„œ ì£¼ìš” ê°€êµ¬ë“¤ì„ ì •í™•íˆ ì°¾ì•„ì£¼ì„¸ìš”.

ì´ë¯¸ì§€ í¬ê¸°: {img_width} x {img_height} í”½ì…€

ìš°ì„ ìˆœìœ„ë³„ ê°€êµ¬ ëª©ë¡:

ğŸ  ëŒ€í˜• ê°€êµ¬ (ìµœìš°ì„ ):
- ì†ŒíŒŒ, ì‡¼íŒŒ (sofa, couch, sectional)
- í° í…Œì´ë¸” (dining table, large coffee table)
- í° ì„ ë°˜/ì±…ì¥ (bookshelf, large cabinet)
- ì¹¨ëŒ€ (bed, mattress)

ğŸª‘ ì¤‘í˜• ê°€êµ¬:
- ì˜ì (chair, armchair, recliner)
- ì‘ì€ í…Œì´ë¸” (side table, coffee table)
- TV/ëª¨ë‹ˆí„° (television, monitor)
- ì‚¬ë‹¤ë¦¬ (ladder, step)

ğŸ§¸ ì†Œí˜• ê°€êµ¬/ì†Œí’ˆ:
- ì¡°ëª… (lamp, floor lamp)
- ì‹ë¬¼/í™”ë¶„ (plant, pot)
- ì¥ì‹í’ˆ (decoration, vase)
- ì¿ ì…˜ (cushion, pillow)

ì¤‘ìš” ì§€ì¹¨:
1. í° ê°€êµ¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¸ì‹
2. ê° ê°€êµ¬ëŠ” ì¶©ë¶„íˆ í° í¬ê¸°ì—¬ì•¼ í•¨ (ìµœì†Œ 50x50 í”½ì…€)
3. ëª…í™•í•˜ê²Œ êµ¬ë¶„ë˜ëŠ” ê°œë³„ ê°€êµ¬ë§Œ í¬í•¨
4. ì• ë§¤í•˜ê±°ë‚˜ ì¼ë¶€ë§Œ ë³´ì´ëŠ” ê²ƒì€ ì œì™¸

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
"furniture_list": [
    {{
    "name": "êµ¬ì²´ì ì¸_ê°€êµ¬_ì´ë¦„",
    "category": "large/medium/small", 
    "priority": "high/medium/low",
    "box": [x1, y1, x2, y2],
    "confidence": "high/medium/low"
    }}
]
}}

ì¢Œí‘œ ê·œì¹™:
- [x1, y1] = ì™¼ìª½ ìœ„ ëª¨ì„œë¦¬
- [x2, y2] = ì˜¤ë¥¸ìª½ ì•„ë˜ ëª¨ì„œë¦¬
- 0 â‰¤ x1 < x2 â‰¤ {img_width}
- 0 â‰¤ y1 < y2 â‰¤ {img_height}

ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
        """

        # GPT API í˜¸ì¶œ
        response = self.open_ai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                                "detail": "high",
                            },
                        },
                    ],
                }
            ],
            max_tokens=3000,
            temperature=0.1,
        )

        # ì‘ë‹µ ì²˜ë¦¬
        response_text = response.choices[0].message.content.strip()
        print(f"ğŸ“ GPT ì‘ë‹µ ë°›ìŒ (ê¸¸ì´: {len(response_text)}ì)")

        # JSON ì¶”ì¶œ
        json_str = response_text.replace("```json", "").replace("```", "").strip()

        try:
            data = json.loads(json_str)
            furniture_list = data.get("furniture_list", [])

            print(f"âœ… ì´ {len(furniture_list)}ê°œ ê°€êµ¬ ë°œê²¬")

            # ì¢Œí‘œ ê²€ì¦ ë° ì •ë¦¬
            valid_furniture = []
            for item in furniture_list:
                name = item.get("name", "unknown")
                category = item.get("category", "medium")
                priority = item.get("priority", "medium")
                box = item.get("box", [])
                confidence = item.get("confidence", "medium")

                if len(box) == 4:
                    x1, y1, x2, y2 = box

                    # ì¢Œí‘œ ë²”ìœ„ í™•ì¸ ë° ìˆ˜ì •
                    x1 = max(0, min(x1, img_width - 1))
                    x2 = max(x1 + 10, min(x2, img_width))
                    y1 = max(0, min(y1, img_height - 1))
                    y2 = max(y1 + 10, min(y2, img_height))

                    # ìµœì†Œ í¬ê¸° í™•ì¸ (50x50 í”½ì…€ ì´ìƒ)
                    if (x2 - x1) >= 50 and (y2 - y1) >= 50:
                        area = (x2 - x1) * (y2 - y1)
                        valid_furniture.append(
                            {
                                "name": name,
                                "category": category,
                                "priority": priority,
                                "box": [x1, y1, x2, y2],
                                "confidence": confidence,
                                "area": area,
                                "size": f"{x2-x1}x{y2-y1}",
                            }
                        )
                        print(
                            f"âœ… {name} ({category}/{priority}): [{x1},{y1},{x2},{y2}] - {x2-x1}x{y2-y1}"
                        )
                    else:
                        print(f"âš ï¸  {name}: ë„ˆë¬´ ì‘ìŒ ({x2-x1}x{y2-y1})")
                else:
                    print(f"âŒ {name}: ì¢Œí‘œ í˜•ì‹ ì˜¤ë¥˜")

            # í¬ê¸°ë³„ ë¶„ë¥˜
            large_furniture, medium_furniture, small_furniture = (
                self.categorize_furniture_by_size(
                    valid_furniture, img_width, img_height
                )
            )

            # ì¤‘ë³µ ì œê±° (í° ê°€êµ¬ë¶€í„° ìš°ì„ )
            all_furniture = large_furniture + medium_furniture + small_furniture
            filtered_furniture = self.filter_overlapping_furniture(
                all_furniture, overlap_threshold=0.6
            )

            print(f"ğŸ“‹ ìµœì¢… ì„ íƒëœ ê°€êµ¬: {len(filtered_furniture)}ê°œ")
            return filtered_furniture

        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
            return []

    def filter_overlapping_furniture(self, furniture_list, overlap_threshold=0.7):
        """ì¤‘ë³µë˜ëŠ” ê°€êµ¬ ì œê±° (í° ê°€êµ¬ ìš°ì„ , ê²¹ì¹˜ëŠ” ë¹„ìœ¨ì´ ë†’ì€ ì‘ì€ ê°€êµ¬ ì œê±°)"""
        print(f"\nğŸ” ì¤‘ë³µ ê°€êµ¬ í•„í„°ë§ ì‹œì‘ (ì„ê³„ê°’: {overlap_threshold*100}%)")

        # ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (í° ê°€êµ¬ë¶€í„°)
        sorted_furniture = sorted(
            furniture_list, key=lambda x: calculate_box_area(x["box"]), reverse=True
        )

        filtered_furniture = []
        removed_count = 0

        for i, current_furniture in enumerate(sorted_furniture):
            current_box = current_furniture["box"]
            current_area = calculate_box_area(current_box)
            current_name = current_furniture["name"]

            is_overlapping = False

            # ì´ë¯¸ ì„ íƒëœ ê°€êµ¬ë“¤ê³¼ ë¹„êµ
            for selected_furniture in filtered_furniture:
                selected_box = selected_furniture["box"]
                selected_name = selected_furniture["name"]

                overlap_ratio = calculate_overlap_ratio(current_box, selected_box)

                if overlap_ratio > overlap_threshold:
                    print(
                        f"âŒ {current_name} (ë©´ì : {current_area}) - {selected_name}ì™€ {overlap_ratio:.1%} ê²¹ì¹¨"
                    )
                    is_overlapping = True
                    removed_count += 1
                    break

            if not is_overlapping:
                filtered_furniture.append(current_furniture)
                print(f"âœ… {current_name} (ë©´ì : {current_area}) - ìœ ì§€")

        print(
            f"ğŸ“Š í•„í„°ë§ ê²°ê³¼: {len(furniture_list)}ê°œ â†’ {len(filtered_furniture)}ê°œ (ì œê±°: {removed_count}ê°œ)"
        )
        return filtered_furniture

    def categorize_furniture_by_size(self, furniture_list, img_width, img_height):
        """ê°€êµ¬ë¥¼ í¬ê¸°ë³„ë¡œ ë¶„ë¥˜"""
        total_image_area = img_width * img_height

        large_furniture = []  # í° ê°€êµ¬ (ì´ë¯¸ì§€ì˜ 3% ì´ìƒ)
        medium_furniture = []  # ì¤‘ê°„ ê°€êµ¬ (ì´ë¯¸ì§€ì˜ 1-3%)
        small_furniture = []  # ì‘ì€ ê°€êµ¬ (ì´ë¯¸ì§€ì˜ 1% ë¯¸ë§Œ)

        for furniture in furniture_list:
            area = calculate_box_area(furniture["box"])
            area_ratio = area / total_image_area

            furniture["area"] = area
            furniture["area_ratio"] = area_ratio

            if area_ratio >= 0.03:  # 3% ì´ìƒ
                large_furniture.append(furniture)
            elif area_ratio >= 0.01:  # 1-3%
                medium_furniture.append(furniture)
            else:  # 1% ë¯¸ë§Œ
                small_furniture.append(furniture)

        print(f"ğŸ“ í¬ê¸°ë³„ ë¶„ë¥˜:")
        print(f"   ğŸ  í° ê°€êµ¬ ({len(large_furniture)}ê°œ): ì´ë¯¸ì§€ì˜ 3% ì´ìƒ")
        print(f"   ğŸª‘ ì¤‘ê°„ ê°€êµ¬ ({len(medium_furniture)}ê°œ): ì´ë¯¸ì§€ì˜ 1-3%")
        print(f"   ğŸ§¸ ì‘ì€ ê°€êµ¬ ({len(small_furniture)}ê°œ): ì´ë¯¸ì§€ì˜ 1% ë¯¸ë§Œ")

        return large_furniture, medium_furniture, small_furniture

    def calculate_size_analysis(self, furniture_list, img_width, img_height):
        """ìƒëŒ€ì  í¬ê¸° ë¶„ì„ ê³„ì‚°"""
        if not furniture_list:
            return {}

        print("\nğŸ“Š ìƒëŒ€ì  í¬ê¸° ë¶„ì„ ì¤‘...")

        # ê¸°ë³¸ ì •ë³´
        total_image_area = img_width * img_height
        largest_furniture_area = max(
            furniture.get("area", 0) for furniture in furniture_list
        )

        # ê° ê°€êµ¬ì˜ ìƒëŒ€ì  í¬ê¸° ì •ë³´ ê³„ì‚°
        furniture_size_comparison = []

        for furniture in furniture_list:
            name = furniture["name"]
            area = furniture.get("area", 0)

            # ë¹„ìœ¨ ê³„ì‚°
            area_ratio_to_image = (area / total_image_area) * 100
            area_ratio_to_largest = (
                (area / largest_furniture_area) * 100
                if largest_furniture_area > 0
                else 0
            )

            # í¬ê¸° ë“±ê¸‰ ê²°ì •
            if area_ratio_to_image >= 3.0:
                size_rank = "ëŒ€í˜•"
            elif area_ratio_to_image >= 1.0:
                size_rank = "ì¤‘í˜•"
            else:
                size_rank = "ì†Œí˜•"

            # ìƒëŒ€ ì ìˆ˜ (ê°€ì¥ í° ê°€êµ¬ = 100ì )
            relative_size_score = round(area_ratio_to_largest, 1)

            size_info = {
                "name": name,
                "absolute_area": area,
                "area_ratio_to_image": f"{area_ratio_to_image:.2f}%",
                "area_ratio_to_largest": f"{area_ratio_to_largest:.1f}%",
                "size_rank": size_rank,
                "relative_size_score": relative_size_score,
            }

            furniture_size_comparison.append(size_info)
            print(
                f"  ğŸ“ {name:15s}: {area:,}pxÂ² ({area_ratio_to_image:.2f}%, {size_rank}, ì ìˆ˜: {relative_size_score})"
            )

        # í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬
        furniture_size_comparison.sort(key=lambda x: x["absolute_area"], reverse=True)

        size_analysis = {
            "image_dimensions": {"width": img_width, "height": img_height},
            "total_image_area": total_image_area,
            "largest_furniture_area": largest_furniture_area,
            "furniture_count": len(furniture_list),
            "size_distribution": {
                "large": len(
                    [
                        f
                        for f in furniture_list
                        if (f.get("area", 0) / total_image_area) >= 0.03
                    ]
                ),
                "medium": len(
                    [
                        f
                        for f in furniture_list
                        if 0.01 <= (f.get("area", 0) / total_image_area) < 0.03
                    ]
                ),
                "small": len(
                    [
                        f
                        for f in furniture_list
                        if (f.get("area", 0) / total_image_area) < 0.01
                    ]
                ),
            },
            "furniture_size_comparison": furniture_size_comparison,
        }

        print(
            f"âœ… í¬ê¸° ë¶„ì„ ì™„ë£Œ: ëŒ€í˜• {size_analysis['size_distribution']['large']}ê°œ, ì¤‘í˜• {size_analysis['size_distribution']['medium']}ê°œ, ì†Œí˜• {size_analysis['size_distribution']['small']}ê°œ"
        )

        return size_analysis

    def crop_furniture_centered_filtered(
        image_path, furniture_list, output_dir="furniture_crops_filtered"
    ):
        """ê° ê°€êµ¬ë¥¼ ì¤‘ì‹¬ì— ë§ì¶°ì„œ í¬ë¡­ (í•„í„°ë§ëœ ë²„ì „)"""
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ì´ë¯¸ì§€ ì—´ê¸°
            img = Image.open(image_path)
            img_width, img_height = img.size
            base_name = os.path.splitext(os.path.basename(image_path))[0]

            print(f"ğŸ¯ {len(furniture_list)}ê°œ ê°€êµ¬ë¥¼ ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­í•©ë‹ˆë‹¤...")

            # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬ (ë©´ì  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
            sorted_furniture = sorted(
                furniture_list, key=lambda x: x.get("area", 0), reverse=True
            )

            cropped_images = []

            for i, furniture in enumerate(sorted_furniture):
                name = furniture["name"]
                category = furniture.get("category", "medium")
                priority = furniture.get("priority", "medium")
                x1, y1, x2, y2 = furniture["box"]
                area = furniture.get("area", 0)

                try:
                    # ì›ë³¸ ê°€êµ¬ í¬ê¸°
                    furniture_width = x2 - x1
                    furniture_height = y2 - y1
                    furniture_center_x = (x1 + x2) // 2
                    furniture_center_y = (y1 + y2) // 2

                    # í¬ë¡­ í¬ê¸° ê²°ì • (ì¹´í…Œê³ ë¦¬ë³„ ì—¬ë°± ì¡°ì •)
                    if category == "large":
                        margin_ratio = 0.05  # í° ê°€êµ¬ëŠ” 5% ì—¬ë°±
                    elif category == "medium":
                        margin_ratio = 0.1  # ì¤‘ê°„ ê°€êµ¬ëŠ” 10% ì—¬ë°±
                    else:
                        margin_ratio = 0.15  # ì‘ì€ ê°€êµ¬ëŠ” 15% ì—¬ë°±

                    margin_x = int(furniture_width * margin_ratio)
                    margin_y = int(furniture_height * margin_ratio)
                    crop_width = furniture_width + 2 * margin_x
                    crop_height = furniture_height + 2 * margin_y

                    # ì¤‘ì‹¬ ë§ì¶¤ í¬ë¡­ ì¢Œí‘œ ê³„ì‚°
                    crop_x1 = max(0, furniture_center_x - crop_width // 2)
                    crop_y1 = max(0, furniture_center_y - crop_height // 2)
                    crop_x2 = min(img_width, crop_x1 + crop_width)
                    crop_y2 = min(img_height, crop_y1 + crop_height)

                    # ê²½ê³„ ì¡°ì •
                    if crop_x2 - crop_x1 < crop_width:
                        crop_x1 = max(0, crop_x2 - crop_width)
                    if crop_y2 - crop_y1 < crop_height:
                        crop_y1 = max(0, crop_y2 - crop_height)

                    # ì´ë¯¸ì§€ í¬ë¡­
                    cropped_img = img.crop((crop_x1, crop_y1, crop_x2, crop_y2))

                    # íŒŒì¼ëª… ì •ë¦¬ (ìš°ì„ ìˆœìœ„ í¬í•¨)
                    safe_name = (
                        name.replace(" ", "_").replace("/", "_").replace("\\", "_")
                    )
                    filename = f"{base_name}_{i+1:02d}_{priority}_{safe_name}.png"
                    filepath = os.path.join(output_dir, filename)

                    # ì €ì¥
                    cropped_img.save(filepath)

                    # ê²°ê³¼ ì •ë³´ ì €ì¥
                    crop_info = {
                        "original_furniture": furniture,
                        "crop_coordinates": [crop_x1, crop_y1, crop_x2, crop_y2],
                        "crop_size": f"{crop_x2-crop_x1}x{crop_y2-crop_y1}",
                        "filename": filename,
                        "filepath": filepath,
                    }
                    cropped_images.append(crop_info)

                    area_ratio = area / (img_width * img_height) * 100
                    print(
                        f"âœ… {i+1:2d}. {name:15s} ({priority:6s}) â†’ {filename} ({crop_x2-crop_x1}x{crop_y2-crop_y1}, {area_ratio:.1f}%)"
                    )

                except Exception as e:
                    print(f"âŒ {name} í¬ë¡­ ì‹¤íŒ¨: {e}")

            print(f"ğŸ‰ ì´ {len(cropped_images)}ê°œ ê°€êµ¬ í¬ë¡­ ì™„ë£Œ!")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")

            return cropped_images

        except Exception as e:
            print(f"âŒ í¬ë¡­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []


class BackgroundRemover:
    # =============================================================================
    # ë‹¨ê³„ 2: Bria Remove Background ëª¨ë¸ ì‚¬ìš©
    # =============================================================================
    def __init__(self, replicate_client):
        self.replicate_client = replicate_client

    def process(
        self,
        input_dir="furniture_crops_filtered",
        output_dir="furniture_no_background_bria",
    ):
        """Bria ëª¨ë¸ì„ ì‚¬ìš©í•œ ë°°ê²½ ì œê±° ì¼ê´„ ì²˜ë¦¬"""
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
            if not os.path.exists(input_dir):
                print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
                return []

            # PNG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            png_files = [f for f in os.listdir(input_dir) if f.lower().endswith(".png")]

            if not png_files:
                print(f"âŒ {input_dir}ì—ì„œ PNG íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []

            print("=" * 60)
            print(f"ğŸ­ Bria ë°°ê²½ ì œê±° ì‘ì—… ì‹œì‘")
            print(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {input_dir}")
            print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
            print(f"ğŸ“Š ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(png_files)}ê°œ")
            print(f"ğŸ¤– ëª¨ë¸: bria/remove-background")
            print("=" * 60)

            processed_files = []
            success_count = 0

            for i, filename in enumerate(png_files, 1):
                input_path = os.path.join(input_dir, filename)

                # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
                name, ext = os.path.splitext(filename)
                output_filename = f"{name}_bria_no_bg{ext}"
                output_path = os.path.join(output_dir, output_filename)

                print(f"\nğŸ”„ [{i}/{len(png_files)}] ì²˜ë¦¬ ì¤‘: {filename}")

                # Bria ë°°ê²½ ì œê±° ì‹œë„
                success = self.remove_background_per_file(input_path, output_path)

                if success:
                    success_count += 1

                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    original_size = os.path.getsize(input_path)
                    new_size = os.path.getsize(output_path)

                    file_info = {
                        "original_file": filename,
                        "input_path": input_path,
                        "output_file": output_filename,
                        "output_path": output_path,
                        "original_size": original_size,
                        "new_size": new_size,
                        "model_used": "bria/remove-background",
                        "status": "success",
                    }
                    processed_files.append(file_info)

                    print(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {original_size:,} â†’ {new_size:,} bytes")
                    print(f"   ğŸ’¾ ì €ì¥ë¨: {output_filename}")

                else:
                    # ì‹¤íŒ¨í•œ ê²½ìš° ì›ë³¸ íŒŒì¼ ë³µì‚¬
                    try:
                        shutil.copy2(input_path, output_path)
                        file_info = {
                            "original_file": filename,
                            "input_path": input_path,
                            "output_file": output_filename,
                            "output_path": output_path,
                            "model_used": "original_copy",
                            "status": "failed_copied_original",
                        }
                        processed_files.append(file_info)
                        print(f"   âš ï¸  ë°°ê²½ ì œê±° ì‹¤íŒ¨, ì›ë³¸ ë³µì‚¬í•¨")
                    except Exception as e:
                        print(f"   âŒ ì›ë³¸ ë³µì‚¬ë„ ì‹¤íŒ¨: {e}")

                # API í˜¸ì¶œ ê°„ ì ì‹œ ëŒ€ê¸° (Rate Limit ë°©ì§€)
                if i < len(png_files):
                    print("   â³ 2ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(2)

            print("\n" + "=" * 60)
            print(f"ğŸ‰ Bria ë°°ê²½ ì œê±° ì‘ì—… ì™„ë£Œ!")
            print(f"âœ… ì„±ê³µ: {success_count}/{len(png_files)}ê°œ")
            print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {output_dir}/")
            print("=" * 60)

            # ê²°ê³¼ ì €ì¥
            result_data = {
                "model_name": "bria/remove-background",
                "input_directory": input_dir,
                "output_directory": output_dir,
                "total_files": len(png_files),
                "successful_removals": success_count,
                "success_rate": f"{success_count/len(png_files)*100:.1f}%",
                "processed_files": processed_files,
                "processing_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            }

            with open("step2_background_removal_bria.json", "w", encoding="utf-8") as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: step2_background_removal_bria.json")

            return processed_files

        except Exception as e:
            print(f"âŒ Bria ë°°ê²½ ì œê±° ì‘ì—… ì˜¤ë¥˜: {e}")
            return []

    def remove_background_per_file(self, image_path, output_path):
        """Bria remove-background ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ì œê±°"""
        try:
            print(f"ğŸ­ Bria ë°°ê²½ ì œê±° ì‹œì‘: {os.path.basename(image_path)}")

            # Bria ëª¨ë¸ ì‹¤í–‰
            output = self.replicate_client.run(
                "bria/remove-background",
                input={
                    "image": open(image_path, "rb"),
                    "content_moderation": False,
                    "preserve_partial_alpha": True,
                },
            )

            print(f"ğŸ” Bria ì‘ë‹µ íƒ€ì…: {type(output)}")

            # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            with open(output_path, "wb") as file:
                file.write(output.read())

            print(f"âœ… Bria ë°°ê²½ ì œê±° ì™„ë£Œ: {os.path.basename(output_path)}")
            return True

        except Exception as e:
            print(f"âŒ Bria ë°°ê²½ ì œê±° ì‹¤íŒ¨ ({os.path.basename(image_path)}): {e}")
            return False


class ImgToModeling:
    def __init__(self, replicate_client):
        self.replicate_client = replicate_client

    # =============================================================================
    # ë‹¨ê³„ 3: HunYuan3D ëª¨ë¸ì„ ì‚¬ìš©í•œ 3D ë³€í™˜
    # =============================================================================
    def run_hunyuan3d(self, image_path, output_filename):
        """HunYuan3D ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°€êµ¬ ì´ë¯¸ì§€ë¥¼ 3D ëª¨ë¸ë¡œ ë³€í™˜"""
        try:
            print(f"ğŸ¨ 3D ë³€í™˜ ì‹œì‘: {os.path.basename(image_path)}")

            input_data = {
                "image": open(image_path, "rb"),
                "remove_background": False,  # ì´ë¯¸ ë°°ê²½ì´ ì œê±°ë¨
            }

            # HunYuan3D ëª¨ë¸ ì‹¤í–‰
            output = self.replicate_client.run(
                "ndreca/hunyuan3d-2:0602bae6db1ce420f2690339bf2feb47e18c0c722a1f02e9db9abd774abaff5d",
                input=input_data,
            )

            print(f"ğŸ” HunYuan3D ì‘ë‹µ íƒ€ì…: {type(output)}")

            # 3D ë©”ì‹œ ë‹¤ìš´ë¡œë“œ
            mesh_url = output["mesh"]
            response = requests.get(mesh_url)

            with open(output_filename, "wb") as file:
                file.write(response.content)

            print(f"âœ… 3D ëª¨ë¸ ìƒì„± ì™„ë£Œ: {output_filename}")
            return True, mesh_url

        except Exception as e:
            print(f"âŒ 3D ë³€í™˜ ì‹¤íŒ¨ ({os.path.basename(image_path)}): {e}")
            return False, None

    def process(
        self, input_dir="furniture_no_background_bria", output_dir="furniture_3d_models"
    ):
        """Bria ë°°ê²½ ì œê±°ëœ ê°€êµ¬ë“¤ì„ 3D ëª¨ë¸ë¡œ ë³€í™˜"""
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
            if not os.path.exists(input_dir):
                print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
                return []

            # PNG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            png_files = [f for f in os.listdir(input_dir) if f.lower().endswith(".png")]

            if not png_files:
                print(f"âŒ {input_dir}ì—ì„œ PNG íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []

            print("=" * 60)
            print(f"ğŸ¨ HunYuan3D 3D ë³€í™˜ ì‘ì—… ì‹œì‘")
            print(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {input_dir}")
            print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
            print(f"ğŸ“Š ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(png_files)}ê°œ")
            print(f"ğŸ¤– ëª¨ë¸: ndreca/hunyuan3d-2")
            print("=" * 60)

            processed_files = []
            success_count = 0
            time_str = datetime.now().strftime("%Y%m%d_%H%M%S")

            for i, filename in enumerate(png_files, 1):
                input_path = os.path.join(input_dir, filename)

                # ì¶œë ¥ íŒŒì¼ëª… ìƒì„± (GLB í˜•ì‹)
                name, _ = os.path.splitext(filename)
                # _bria_no_bg ì œê±°
                clean_name = name.replace("_bria_no_bg", "")
                output_filename = f"{clean_name}_3d_{time_str}.glb"
                output_path = os.path.join(output_dir, output_filename)

                print(f"\nğŸ”„ [{i}/{len(png_files)}] 3D ë³€í™˜ ì¤‘: {filename}")

                # HunYuan3D 3D ë³€í™˜ ì‹œë„
                success, mesh_url = self.run_hunyuan3d(input_path, output_path)

                if success:
                    success_count += 1

                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    original_size = os.path.getsize(input_path)
                    model_size = (
                        os.path.getsize(output_path)
                        if os.path.exists(output_path)
                        else 0
                    )

                    file_info = {
                        "original_file": filename,
                        "input_path": input_path,
                        "output_file": output_filename,
                        "output_path": output_path,
                        "original_size": original_size,
                        "model_size": model_size,
                        "mesh_url": mesh_url,
                        "model_used": "ndreca/hunyuan3d-2",
                        "status": "success",
                    }
                    processed_files.append(file_info)

                    print(f"   ğŸ“Š ì›ë³¸ í¬ê¸°: {original_size:,} bytes")
                    print(f"   ğŸ“Š 3D ëª¨ë¸ í¬ê¸°: {model_size:,} bytes")
                    print(f"   ğŸ’¾ ì €ì¥ë¨: {output_filename}")

                else:
                    file_info = {
                        "original_file": filename,
                        "input_path": input_path,
                        "output_file": output_filename,
                        "output_path": output_path,
                        "model_used": "ndreca/hunyuan3d-2",
                        "status": "failed",
                    }
                    processed_files.append(file_info)
                    print(f"   âŒ 3D ë³€í™˜ ì‹¤íŒ¨")

                # API í˜¸ì¶œ ê°„ ì ì‹œ ëŒ€ê¸° (Rate Limit ë°©ì§€)
                if i < len(png_files):
                    print("   â³ 5ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(5)  # 3D ë³€í™˜ì€ ë” ë§ì€ ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ

            print("\n" + "=" * 60)
            print(f"ğŸ‰ 3D ë³€í™˜ ì‘ì—… ì™„ë£Œ!")
            print(f"âœ… ì„±ê³µ: {success_count}/{len(png_files)}ê°œ")
            print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {output_dir}/")
            print("=" * 60)

            # ê²°ê³¼ ì €ì¥
            result_data = {
                "model_name": "ndreca/hunyuan3d-2",
                "input_directory": input_dir,
                "output_directory": output_dir,
                "total_files": len(png_files),
                "successful_conversions": success_count,
                "success_rate": f"{success_count/len(png_files)*100:.1f}%",
                "processed_files": processed_files,
                "processing_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "timestamp": time_str,
            }

            with open("step3_3d_conversion_hunyuan.json", "w", encoding="utf-8") as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: step3_3d_conversion_hunyuan.json")

            return processed_files

        except Exception as e:
            print(f"âŒ 3D ë³€í™˜ ì‘ì—… ì˜¤ë¥˜: {e}")
            return []
